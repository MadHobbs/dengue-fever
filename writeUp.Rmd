---
title: "Predicting cases of dengue feaver based on evnivornemtnal data using a random forest model."
author: "Madison Hobbs and Jenn Havens"
output:
  pdf_document: default
  html_document: default
---
```{r loadData, echo = F , warning=FALSE, include=FALSE}

knitr::opts_chunk$set(echo = F, message=FALSE, warning=FALSE, cache=TRUE, 
                      fig.width=7, fig.height=4, fig.align = "center")


require(rpart)
require(caret)
library(RANN)
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggcorrplot)
library(corrplot)
library(lubridate)
library(zoo)
library(xts)
library(sp)
library(maptools)
library(intervals)
library(spacetime)
library(FNN)
library(gstat)
library(reshape)
library(automap)
library(hydroTSM)
library(hydroGOF)

TestPred <- read.csv("./DengAI_Predicting_Disease_Spread_-_Test_Data_Features.csv")

TrainPred <- read.csv("./DengAI_Predicting_Disease_Spread_-_Training_Data_Features.csv")
TrainResp <- read.csv("./DengAI_Predicting_Disease_Spread_-_Training_Data_Labels.csv")

TrainFull <- full_join(TrainResp, TrainPred, by = c("city", "year", "weekofyear"))


```

##Introduction:
Cases of dengue fever are related to the [current](http://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0001648) and [past](http://www.sciencedirect.com/science/article/pii/S0001706X07001271) climate. Environmental data can be used for predicting patterns in rates of dengue fever. Patterns of cases known in advance can used as an early warning system to help local authorities prepare for unusually high numbers of cases as well as informing which areas may need the most outside assistance.


##The Model
We created two (2) predictive models, one for each of the cities of interest: San Juan, Puerto Rico and Iquitos, PerÃº. Our model is a random forest algorithm which was trained on data from each city individually. 


### Missing Values:

First, we ask how many values in our data are NA?

```{r howManyNA}
# what percentage of data is NA?
round(sum(is.na(TrainFull))/(dim(TrainFull)[1]*dim(TrainFull)[2]), 3)
```

Only 1.5% of our data is missing. Because there are relatively few missing values, and because having missing weeks will complicate our time series analyses, we decide to impute missing values. We use imputation via bagging (from the caret package). According to their documentation: " Imputation via bagging fits a bagged tree model for each predictor (as a function of all the others). This method is simple, accurate and accepts missing values, but it has much higher computational cost. " Luckily, it doesn't take too long for bagging to impute the relatively few misssing values on our data.

```{r bagToFillNAs}
set.seed(6)
impTrainFull <- preProcess(TrainFull, "bagImpute")
TrainFull_noNA <- predict(impTrainFull, TrainFull)
```

# Variable Selection

## Temperature

We think that the station-measured temperature would be preferable, because these are not measured from satellite or estimated from a model. The [NOAA Dengue Forecasting project](http://dengueforecasting.noaa.gov) also notes in their reference guide, "Environmental data sources for the Dengue Project," that, "Ground observations are generally an optimal representation of actual local conditions." 

We should also think about whether to choose minimum temperature, maximum temperature, average temperature, or diurnal temperature range. We suspect that these variables are redundant.

```{r tempCor, echo=F}
temps <- TrainFull_noNA %>% select(station_max_temp_c,station_avg_temp_c, station_min_temp_c, station_diur_temp_rng_c) 

corr_matrix <- cor(temps)
corr_pmat <- cor_pmat(temps)
# they are all significantly correlated 
#all(corr_pmat < 0.05)
```

In fact, all pairwise correlations between the four measures of temperature are significant. We can see these strong correlations represented in the correlation plot below:


```{r tempCorPlot}
#ggcorrplot(corr_matrix, hc.order = TRUE)
corrplot(corr_matrix, method = "color")
```


Because of this correlation and because [past studies](https://bmcpublichealth.biomedcentral.com/track/pdf/10.1186/s12889-016-2923-2?site=http://bmcpublichealth.biomedcentral.com) have found that mean temperature was significantly associated with dengue rates, but maximum temperature and minimum were not always significant, we will proceed with mean temperature as the only temperature variable.

## Precipitation

Variable descriptions are [avalible](https://www.drivendata.org/competitions/44/dengai-predicting-disease-spread/page/82/). 

There are three measures of precipitation. One is station_precip_mm which is the total daily precipitation as measured by [NOAA's GHCN weather stations](https://www.ncdc.noaa.gov/ghcn-daily-description). Another is precipitation_amt_mm which represents total precipitation as measured by PERSIANN satellites. The third and forth, reanalysis_sat_precip_amt_mm and reanalysis_precip_amt_kg_per_m2 are both generated by [NOAA's NCEP Climate Forecast System Reanalysis](https://climatedataguide.ucar.edu/climate-data/climate-forecast-system-reanalysis-cfsr). 

We should choose one of these precipitation  measures for the model, since these four precipitation measures all measure approximately the same thing. According to the [NOAA Dengue Forecasting recommendations](http://dengueforecasting.noaa.gov),  "remotely sensed observations are generally an excellent observation of precipitation and vegetation conditions for a location." With the multiple sources for total precipitation, we decide to use only the satellite measured total precipitation for each city to build our model.

### Humidity and Dewpoint

Specific humidity, relative humidity, and dew point are all provided and are all measured using [NOAA's NCEP Climate Forecast System Reanalysis](https://climatedataguide.ucar.edu/climate-data/climate-forecast-system-reanalysis-cfsr). All three measures are significantly correlated, as seen below.

```{r}
humids <- TrainFull_noNA %>% select(reanalysis_relative_humidity_percent, reanalysis_specific_humidity_g_per_kg, reanalysis_dew_point_temp_k) 

corr_matrix <- cor(humids)
corr_pmat <- cor_pmat(humids)

corr_pmat

# they are all significantly correlated 
#all(corr_pmat < 0.05)

#ggcorrplot(corr_matrix, hc.order = TRUE)
corrplot(corr_matrix, method = "color")

```


Since these measure roughly the same information, we opt to include only one in our model. Relative humidity is the measure most often used in literature we have read. It is also an easy-to-find measure, making our model more user-friendly. Therefore, we use only relative humidity in the model.

## Creating Lagged Data

We separate San Juan and Iquitos data to produce two models, one to predict weekly dengue fever cases in San Juan and the other in Iquitos. This is because weather and vegetation will behave differently in relation to time between both locations, because these are locations separated by distance, climate, and ecosystem. 

At the same time, we create two lag variables for each site: temperature lag and precipitation lag. The lagged temperature and precipitation variables record, respectively, what the temperature or precipitation was 12 weeks prior for the observation at hand. 

Time laged environmental variables [have been shown to be a signifigant predictors](http://www.sciencedirect.com/science/article/pii/S0001706X07001271). Specifically we consider temperature, precipitation, and relative humidity. 

```{r makeTimeLags}
lag_num_weeks = 12

#make on col which gives year and week of year info
tempData <- mutate(TrainFull_noNA, year_week_temp = paste(as.character(year), "_", as.character(weekofyear), sep="")) %>% mutate(lag_year_week_temp = paste(year(as.Date(week_start_date)-weeks(lag_num_weeks)), "_", week(as.Date(week_start_date)-weeks(lag_num_weeks)), sep=""))

#make year_week and lag_year_week of yyyy_ww format
tempData <- mutate(tempData, year_week = ifelse(nchar(year_week_temp) == 7, year_week_temp, sub("_", "_0", year_week_temp))) %>% mutate(lag_year_week = ifelse(nchar(lag_year_week_temp) == 7, lag_year_week_temp, sub("_", "_0", lag_year_week_temp)))

tempDataIQ <- filter(tempData, city == "iq")
tempDataSJ <- filter(tempData, city == "sj")

### San Juan Data for Model
#want lag for: precipitation_amt_mm and station_avg_temp_c for SJ
lag_week_temp <- c()
lag_week_precip <- c()
lag_week_humid <- c()
for (i in 1:length(tempDataSJ$lag_year_week)){
  if (sum(grepl(tempDataSJ$lag_year_week[i], tempDataSJ$year_week)) == 1){
    #find correct index for lag data and add that data to vectors
    lagWeeki <- grep(tempDataSJ$lag_year_week[i], tempDataSJ$year_week)
    lag_week_temp <- c(lag_week_temp, tempDataSJ$station_avg_temp_c[lagWeeki])
    lag_week_precip <- c(lag_week_precip, tempDataSJ$precipitation_amt_mm[lagWeeki])
    lag_week_humid <- c(lag_week_humid, tempDataSJ$reanalysis_relative_humidity_percent[lagWeeki])
  }else {
    lag_week_temp <- c(lag_week_temp, NA)
    lag_week_precip <- c(lag_week_precip, NA)
    lag_week_humid <- c(lag_week_humid, NA)
  }
}           

tempDataSJ$temp_lag <- lag_week_temp
tempDataSJ$precip_lag <- lag_week_precip
tempDataSJ$humidity_lag <- lag_week_humid 

# select only the predictors we want for the model
sj_data_for_model <- select(tempDataSJ, total_cases, year, weekofyear, ndvi_ne, ndvi_nw, ndvi_se, ndvi_sw, precipitation_amt_mm, precip_lag, station_avg_temp_c, temp_lag, reanalysis_relative_humidity_percent, humidity_lag)


### Iquitos Data for Model
#want lag for: precipitation_amt_mm and station_avg_temp_c for IQ
lag_week_temp <- c()
lag_week_precip <- c()
lag_week_humid <- c()
for (i in 1:length(tempDataIQ$lag_year_week)){
  if (sum(grepl(tempDataIQ$lag_year_week[i], tempDataIQ$year_week)) == 1){
    #find correct index for lag data and add that data to vectors
    lagWeeki <- grep(tempDataIQ$lag_year_week[i], tempDataIQ$year_week)
    lag_week_temp <- c(lag_week_temp, tempDataIQ$station_avg_temp_c[lagWeeki])
    lag_week_precip <- c(lag_week_precip, tempDataIQ$precipitation_amt_mm[lagWeeki])
    lag_week_humid <- c(lag_week_humid, tempDataIQ$reanalysis_relative_humidity_percent[lagWeeki])
  }else {
    lag_week_temp <- c(lag_week_temp, NA)
    lag_week_precip <- c(lag_week_precip, NA)
    lag_week_humid <- c(lag_week_humid, NA)
  }
}           

tempDataIQ$temp_lag <- as.numeric(lag_week_temp)
tempDataIQ$precip_lag <- as.numeric(lag_week_precip)
tempDataIQ$humidity_lag <- as.numeric(lag_week_humid)

# select only the predictors we want for the model
iq_data_for_model <- select(tempDataIQ, total_cases, year, weekofyear, ndvi_ne, ndvi_nw, ndvi_se, ndvi_sw, precipitation_amt_mm, precip_lag, station_avg_temp_c, temp_lag, reanalysis_relative_humidity_percent, humidity_lag)

iq_data_for_model <- filter(iq_data_for_model, humidity_lag != "NA")
sj_data_for_model <- filter(sj_data_for_model, humidity_lag != "NA")

# get good names for columns

iq_data_for_model <- iq_data_for_model %>% dplyr::rename(week_of_year = weekofyear) %>% dplyr::rename(relative_humidity_percent = reanalysis_relative_humidity_percent)

sj_data_for_model <- sj_data_for_model %>% dplyr::rename(week_of_year = weekofyear, relative_humidity_percent = reanalysis_relative_humidity_percent)
```


## Model Evaluation

Michael J. Kane et. al compared a time series Random Forest model and an ARIMA model to predict avian influenza H5N1 cases, detailed in their [paper](https://link.springer.com/article/10.1186/1471-2105-15-276). They found that a Random Forest time series model with time lag variables out-performed the prospective ARIMA model in predicting H5N1 cases per week in Egypt.

To assess their model, Kane et. al built a Random Forest model on 30 weeks, then used that model to predict the next week. The simulation steps forward week by iteratively adding the next week of data, building a new model, and predicting the number of cases in the following week. 

Inspired by their work, we was used for prediction of avian influenza H5N1 outbreaks. The model was assessed by taking data from the previous 30 weeks to predict for the next week. The simulation steps forward interatively adding new data for each week, the new model using the updated data to predict the next week, and comparing to the true number of cases.

Moving in steps of 30 weeks, we train the model on 30 weeks, then predict the next week. 

We'll assess our model's performance by computing the error (root mean squared error) between the model's predicted number of cases and the actual number of cases for each week. The Driven Data team uses mean absolute error to assess models, so we will, too.

```{r errorRateFunctions}
# returns Mean Absolute Error
# error is defined as actual - predicted
MAE <- function(error)
{
    mean(abs(error))
}

# returns Root Mean Squared Error
# error is defined as actual - predicted
RMSE <- function(error)
{
  sqrt(mean(error^2))
}
```


## San Juan

###Testing with current environemntal data, lagged environmental data, and date information

```{r buildWallSJ}
step <- 30
predictions <- rep(NA, step)

index_to_predict = step + 1
while(index_to_predict <= length(sj_data_for_model$total_cases)) {

  # use previous "step" number of weeks to build model
  data <- slice(sj_data_for_model, 1:(index_to_predict-1))
  
  model <- train(total_cases ~ ., data = data, method = "rf", trControl =  trainControl(method = "oob"), ntree = 100, tuneGrid = data.frame(mtry = 1:12), importance = TRUE)
  
  # predict on single observation:  the next week, the index_to_predict
  predicted_num_cases <- predict(model, slice(sj_data_for_model, index_to_predict))
  
  predictions <- c(predictions, predicted_num_cases)
  
  index_to_predict = index_to_predict + 1
}

actual <- sj_data_for_model$total_cases[31:length(sj_data_for_model$total_cases)]
predicted <- predictions[31:length(predictions)]

RMSE(predicted - actual)
MAE(predicted - actual)

# ranges from 0 to 100, scaled to data
nrmse(predicted, actual)
```



```{r testWallSJ}
sj_prospective_preds <- data.frame(sj_data_for_model$year[31:length(sj_data_for_model$total_cases)], sj_data_for_model$week_of_year[31:length(sj_data_for_model$total_cases)], actual, predicted)
colnames(sj_prospective_preds) = c("year", "week_of_year", "actual", "predicted")
sj_prospective_preds <- sj_prospective_preds %>% mutate(week_index = row_number()) %>% gather(actual_or_predicted, dengue_cases_in_week, -year, -week_of_year, -week_index)

ggplot(sj_prospective_preds, aes(x = week_index, y = dengue_cases_in_week, col = actual_or_predicted)) + geom_line() + ggtitle("San Juan: Actual vs. Predicted Weekly Dengue Cases")
```

### With environmental varibles only

```{r buildWcurentEnviroSJ}
test <- sample_n(sj_data_for_model, 0.1*length(sj_data_for_model$total_cases))
train <- anti_join(sj_data_for_model, test)

set.seed(92)
sj_model <- train(total_cases ~ ., data = select(train, -year, -week_of_year, -temp_lag, -precip_lag, -humidity_lag), method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 1:7), importance = TRUE)
sj_model
set.seed(82)
sj_model <- train(total_cases ~ ., data = select(sj_data_for_model, -year, -week_of_year, -temp_lag, -precip_lag, -humidity_lag), method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 1), importance = TRUE)
sj_model

predictions <- predict(sj_model, test)
RMSE(predictions - test$total_cases)

nrmse(predictions, test$total_cases)

```

```{r testWcurentEnviroSJ}
sj_preds <- data.frame(test$year, test$week_of_year, test$total_cases, predictions)
colnames(sj_preds) = c("year", "week_of_year", "actual", "predicted")
sj_preds <- sj_preds %>% mutate(week_index = row_number()) %>% gather(actual_or_predicted, dengue_cases_in_week, -year, -week_of_year, -week_index)

ggplot(sj_preds, aes(x = week_index, y = dengue_cases_in_week, col = actual_or_predicted)) + geom_line() + ggtitle("San Juan: Actual vs. Predicted - Climate Variables Only")
```

### With Lagged Temperature, Humidity, and Precipitation

```{r buildWlagSJ}
set.seed(98)
test <- sample_n(sj_data_for_model, 0.1*length(sj_data_for_model$total_cases))
train <- anti_join(sj_data_for_model, test)

set.seed(97)
sj_model <- train(total_cases ~ ., data = select(train, -year, -week_of_year), method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 1:10), importance = TRUE)
sj_model
set.seed(81)
sj_model <- train(total_cases ~ ., data = select(sj_data_for_model, -year, -week_of_year), method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 10), importance = TRUE)
sj_model

# save this model as rda
save(sj_model, file = "sj_model.rda")

predictions <- predict(sj_model, test)
RMSE(predictions - test$total_cases)
```

When taking ndvi out of the model, the RMSE rises to 24.66074. 

```{r testWlagSJ}
sj_preds <- data.frame(test$year, test$week_of_year, test$total_cases, predictions)
colnames(sj_preds) = c("year", "week_of_year", "actual", "predicted")
sj_preds <- sj_preds %>% mutate(week_index = row_number()) %>% gather(actual_or_predicted, dengue_cases_in_week, -year, -week_of_year, -week_index)

ggplot(sj_preds, aes(x = week_index, y = dengue_cases_in_week, col = actual_or_predicted)) + geom_line() + ggtitle("San Juan: Actual vs. Predicted - Climate Variables with Lags")
```

## Iquitos

###Testing with current environemntal data, lagged environemntal data and date information

```{r buildWallIQ}
step <- 30
predictions <- rep(NA, step)

index_to_predict = step + 1
while(index_to_predict <= length(iq_data_for_model$total_cases)) {

  # use previous "step" number of weeks to build model
  data <- slice(iq_data_for_model, (index_to_predict-step):(index_to_predict-1))
  
  model <- train(total_cases ~ ., data = data, method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 1:12), importance = TRUE)
  
  # predict on single observation:  the next week, the index_to_predict
  predicted_num_cases <- predict(model, slice(iq_data_for_model, index_to_predict))
  
  predictions <- c(predictions, predicted_num_cases)
  
  index_to_predict = index_to_predict + 1
}

actual <- iq_data_for_model$total_cases[31:length(iq_data_for_model$total_cases)]
predicted <- predictions[31:length(predictions)]

RMSE(predicted - actual)
MAE(predicted - actual)

nrmse(predicted, actual)
```

```{r testWallIQ}
iq_prospective_preds <- data.frame(iq_data_for_model$year[31:length(iq_data_for_model$total_cases)], iq_data_for_model$week_of_year[31:length(iq_data_for_model$total_cases)], actual, predicted)
colnames(iq_prospective_preds) = c("year", "week_of_year", "actual", "predicted")
iq_prospective_preds <- iq_prospective_preds %>% mutate(week_index = row_number()) %>% gather(actual_or_predicted, dengue_cases_in_week, -year, -week_of_year, -week_index)

ggplot(iq_prospective_preds, aes(x = week_index, y = dengue_cases_in_week, col = actual_or_predicted)) + geom_line() + ggtitle("Iquitos : Actual vs. Predicted Weekly Dengue Cases")
```

### With environmental varibles only 

```{r buildWcurentEnviroIQ}
set.seed(44)
test <- sample_n(iq_data_for_model, 0.1*length(iq_data_for_model$total_cases))
train <- anti_join(iq_data_for_model, test)

set.seed(54)
iq_model <- train(total_cases ~ ., data = select(train, -year, -week_of_year, -precip_lag, -temp_lag, -humidity_lag), method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 1:7), importance = TRUE)
iq_model
set.seed(45)
iq_model <- train(total_cases ~ ., data = select(iq_data_for_model, -year, -week_of_year, -temp_lag, -precip_lag, -humidity_lag), method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 1), importance = TRUE)
iq_model

predictions <- predict(iq_model, test)
#RMSE(predictions - test$total_cases)
nrmse(predictions, test$total_cases)

```

```{r testWcurentEnviroIQ}
iq_preds <- data.frame(test$year, test$week_of_year, test$total_cases, predictions)
colnames(iq_preds) = c("year", "week_of_year", "actual", "predicted")
iq_preds <- iq_preds %>% mutate(week_index = row_number()) %>% gather(actual_or_predicted, dengue_cases_in_week, -year, -week_of_year, -week_index)

ggplot(iq_preds, aes(x = week_index, y = dengue_cases_in_week, col = actual_or_predicted)) + geom_line() + ggtitle("Iquitos: Actual vs. Predicted - Climate Variables Only")
```

### With Lagged Temperature, Humidity, and Precipitation

```{r buildWlagIQ}
set.seed(76)
test <- sample_n(iq_data_for_model, 0.1*length(iq_data_for_model$total_cases))
train <- anti_join(iq_data_for_model, test)

set.seed(91)
iq_model <- train(total_cases ~ ., data = select(train, -year, -week_of_year), method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 1:10), importance = TRUE)
iq_model
set.seed(84)
iq_model <- train(total_cases ~ ., data = select(iq_data_for_model, -year, -week_of_year), method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 1), importance = TRUE)
iq_model

# save this model as rda
save(iq_model, file = "iq_model.rda")

predictions <- predict(iq_model, test)
#RMSE(predictions - test$total_cases)
nrmse(predictions, test$total_cases)

```

```{r testWlagIQ}
iq_preds <- data.frame(test$year, test$week_of_year, test$total_cases, predictions)
colnames(iq_preds) = c("year", "week_of_year", "actual", "predicted")
iq_preds <- iq_preds %>% mutate(week_index = row_number()) %>% gather(actual_or_predicted, dengue_cases_in_week, -year, -week_of_year, -week_index)

ggplot(iq_preds, aes(x = week_index, y = dengue_cases_in_week, col = actual_or_predicted)) + geom_line() + ggtitle("Iquitos: Actual vs. Predicted - Climate Variables with Lags")
```
