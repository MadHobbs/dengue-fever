---
title: "Data Exlporation"
author: "Jenn Havens and Madison Hobbs"
date: "November & December 2017"
output: pdf_document
---

```{r loadData, echo = F , warning=FALSE, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, cache=TRUE, 
                      fig.width=7, fig.height=4, fig.align = "center")

require(tidyverse)
require(rpart)
require(caret)
require(ggcorrplot)
library(RANN)
library(dplyr)
library(ggcorrplot)
library(lubridate)
library(hydroGOF)

TestPred <- read.csv("./DengAI_Predicting_Disease_Spread_-_Test_Data_Features.csv")

TrainPred <- read.csv("./DengAI_Predicting_Disease_Spread_-_Training_Data_Features.csv")
TrainResp <- read.csv("./DengAI_Predicting_Disease_Spread_-_Training_Data_Labels.csv")

TrainFull <- full_join(TrainResp, TrainPred, by = c("city", "year", "weekofyear"))


```


# Preliminary Data Exploration

```{r somePlots , echo = F , warning=FALSE}

enviroPredNames <- colnames(TrainFull)[6:25]



ggplot(data = TrainFull) + geom_point(aes(x=precipitation_amt_mm, y=total_cases)) + facet_grid(city~.)

ggplot(data = TrainFull) + geom_point(aes(x=reanalysis_air_temp_k, y=total_cases)) + facet_grid(city~.)

ggplot(data = TrainFull) + geom_point(aes(x=reanalysis_precip_amt_kg_per_m2, y=total_cases)) + facet_grid(city~.)

ggplot(data = TrainFull) + geom_point(aes(x=reanalysis_tdtr_k, y=total_cases)) + facet_grid(city~.)

ggplot(data = TrainFull) + geom_point(aes(x=station_avg_temp_c, y=total_cases)) + facet_grid(city~.)


ggplot(data = TrainFull) + geom_point(aes(x=station_precip_mm, y=total_cases)) + facet_grid(city~.)


```

```{r seasonalAnalysis , echo = F, warning=FALSE}

#there are 13 weeks in a season

findSeason <- function(week){
  if (week < 10){
    return(1)
  } else if (week < 20){
    return(2)
  } else if (week < 31){
    return(3)
  } else {
    return(4)
  }
}


TrainFullTest <- TrainFull


season <- c()
for (i in 1:length(TrainFullTest$weekofyear)){
  season <- c(season, findSeason(TrainFullTest$weekofyear[i]))
}
TrainFullTest <- cbind(TrainFullTest, season)

ggplot(data = TrainFullTest) + geom_point(aes(x=season, y=total_cases)) + facet_grid(city~.)

ggplot(data = TrainFullTest) + geom_point(aes(x=weekofyear, y=total_cases)) + facet_grid(city~.)

ggplot(data = TrainFullTest) + geom_point(aes(x=week_start_date, y=total_cases)) + facet_grid(city~.)


```

# Missing Values

We impute missing values using imputation via bagging (from the caret package). According to their documentation: " Imputation via bagging fits a bagged tree model for each predictor (as a function of all the others). This method is simple, accurate and accepts missing values, but it has much higher computational cost. "

```{r}
set.seed(6)
impTrainFull <- preProcess(TrainFull, "bagImpute")
TrainFull_noNA <- predict(impTrainFull, TrainFull)
head(TrainFull_noNA)
anyNA(TrainFull_noNA)
```

# Variable Selection

## Temperature

We think that the station-measured temperature would be preferable, because these are not measured from satellite or estimated from a model. 

We should also think about whether to choose minimum temperature, maximum temperature, average temperature, or diurnal temperature range. We suspect that these variables are redundant, and we can clearly see from the data below:

```{r}
temps <- TrainFull_noNA %>% select(station_max_temp_c,station_avg_temp_c, station_min_temp_c, station_diur_temp_rng_c) 

corr_matrix <- cor(temps)
corr_pmat <- cor_pmat(temps)
# they are all significantly correlated 
all(corr_pmat < 0.05)
```

All pairwise correlations betweent the four measures of temperature are significant. We can see these strong correlations represented in the correlation plot below:

```{r}
ggcorrplot(corr_matrix, hc.order = TRUE)
```

Note that Choi et. al say : "Mean temperature was significantly associated with dengue incidence in all three provinces, but incidence did not correlate well with maximum temperature in Banteay Meanchey, nor with minimum temperature in Kampong Thom at a lag of three months in the negative binomial model." We are inclined to only use mean temperature. 

## Precipitation

Variable descriptions https://www.drivendata.org/competitions/44/dengai-predicting-disease-spread/page/82/. 

There are three measures of precipitation. One is station_precip_mm which is the total daily precipitation as measured by NOAA's GHCN weather stations (https://www.ncdc.noaa.gov/ghcn-daily-description). Another is precipitation_amt_mm which represents total precipitation as measured by PERSIANN satellites. The third and forth, reanalysis_sat_precip_amt_mm and reanalysis_precip_amt_kg_per_m2 are both generated by NOAA's NCEP Climate Forecast System Reanalysis (https://climatedataguide.ucar.edu/climate-data/climate-forecast-system-reanalysis-cfsr). 

We should choose one of these precipitation  measures for the model, since these four precipitation measures all measure approximately the same thing. According to the NOAA Dengue Forecasting recommendations (http://dengueforecasting.noaa.gov),  "remotely sensed observations are generally an excellent observation of precipitation and vegetation conditions for a location." With the multiple sources for total precipitation, we decide to use only the satellite measured total precipitation for each city to build our model.


### Which Air Temperature Measures Should Be Included?

Note that Choi et. al say : "Mean temperature was significantly associated with dengue incidence in all three provinces, but incidence did not correlate well with maximum temperature in Banteay Meanchey, nor with minimum temperature in Kampong Thom at a lag of three months in the negative binomial model." I'm inclined to only use mean temperature. 

### Should humidity and Dewpoint be included?

Specific humidity, relative humidity, and dew point are all provided and are all measured using NOAA's NCEP Climate Forecast System Reanalysis. All three measures are significantly correlated, as seen below.

```{r}
humids <- TrainFull_noNA %>% select(reanalysis_relative_humidity_percent, reanalysis_specific_humidity_g_per_kg, reanalysis_dew_point_temp_k) 

corr_matrix <- cor(humids)
corr_pmat <- cor_pmat(humids)
# they are all significantly correlated 
all(corr_pmat < 0.05)

ggcorrplot(corr_matrix, hc.order = TRUE)
```


Since these measure roughly the same information, we opt to include only one in our model. Relative humidity is the measure most often used in literature we have read. It is also an easy-to-find measure, making our model more user-friendly. Therefore, we use only relative humidity in the model.

## Creating Data for Model and Lagged Data

We separate San Juan and Iquitos data to produce two models, one to predict weekly dengue fever cases in San Juan and the other in Iquitos. This is because weather and vegetation will behave differently in relation to time between both locations, because these are locations separated by distance, climate, and ecosystem. 

At the same time, we create two lag variables for each site: temperature lag and precipitation lag. The lagged temperature and precipitation variables record, respectively, what the temperature or precipitation was 12 weeks prior for the observation at hand. 

Time laged environmental variables have been shown to be a signifigant predictors. Specifically we consider temperature and relative humidity (Wu et al 2007). 


```{r makeTimeLags}
lag_num_weeks = 12

#make on col which gives year and week of year info
tempData <- mutate(TrainFull_noNA, year_week_temp = paste(as.character(year), "_", as.character(weekofyear), sep="")) %>% mutate(lag_year_week_temp = paste(year(as.Date(week_start_date)-weeks(lag_num_weeks)), "_", week(as.Date(week_start_date)-weeks(lag_num_weeks)), sep=""))

#make year_week and lag_year_week of yyyy_ww format
tempData <- mutate(tempData, year_week = ifelse(nchar(year_week_temp) == 7, year_week_temp, sub("_", "_0", year_week_temp))) %>% mutate(lag_year_week = ifelse(nchar(lag_year_week_temp) == 7, lag_year_week_temp, sub("_", "_0", lag_year_week_temp)))

tempDataIQ <- filter(tempData, city == "iq")
tempDataSJ <- filter(tempData, city == "sj")

### San Juan Data for Model
#want lag for: precipitation_amt_mm and station_avg_temp_c for SJ
lag_week_temp <- c()
lag_week_precip <- c()
lag_week_humid <- c()
for (i in 1:length(tempDataSJ$lag_year_week)){
  if (sum(grepl(tempDataSJ$lag_year_week[i], tempDataSJ$year_week)) == 1){
    #find correct index for lag data and add that data to vectors
    lagWeeki <- grep(tempDataSJ$lag_year_week[i], tempDataSJ$year_week)
    lag_week_temp <- c(lag_week_temp, tempDataSJ$station_avg_temp_c[lagWeeki])
    lag_week_precip <- c(lag_week_precip, tempDataSJ$precipitation_amt_mm[lagWeeki])
    lag_week_humid <- c(lag_week_humid, tempDataSJ$reanalysis_relative_humidity_percent[lagWeeki])
  }else {
    lag_week_temp <- c(lag_week_temp, NA)
    lag_week_precip <- c(lag_week_precip, NA)
    lag_week_humid <- c(lag_week_humid, NA)
  }
}           

tempDataSJ$temp_lag <- lag_week_temp
tempDataSJ$precip_lag <- lag_week_precip
tempDataSJ$humidity_lag <- lag_week_humid 

# select only the predictors we want for the model
sj_data_for_model <- select(tempDataSJ, total_cases, year, weekofyear, ndvi_ne, ndvi_nw, ndvi_se, ndvi_sw, precipitation_amt_mm, precip_lag, station_avg_temp_c, temp_lag, reanalysis_relative_humidity_percent, humidity_lag)


### Iquitos Data for Model
#want lag for: precipitation_amt_mm and station_avg_temp_c for IQ
lag_week_temp <- c()
lag_week_precip <- c()
lag_week_humid <- c()
for (i in 1:length(tempDataIQ$lag_year_week)){
  if (sum(grepl(tempDataIQ$lag_year_week[i], tempDataIQ$year_week)) == 1){
    #find correct index for lag data and add that data to vectors
    lagWeeki <- grep(tempDataIQ$lag_year_week[i], tempDataIQ$year_week)
    lag_week_temp <- c(lag_week_temp, tempDataIQ$station_avg_temp_c[lagWeeki])
    lag_week_precip <- c(lag_week_precip, tempDataIQ$precipitation_amt_mm[lagWeeki])
    lag_week_humid <- c(lag_week_humid, tempDataIQ$reanalysis_relative_humidity_percent[lagWeeki])
  }else {
    lag_week_temp <- c(lag_week_temp, NA)
    lag_week_precip <- c(lag_week_precip, NA)
    lag_week_humid <- c(lag_week_humid, NA)
  }
}           

tempDataIQ$temp_lag <- as.numeric(lag_week_temp)
tempDataIQ$precip_lag <- as.numeric(lag_week_precip)
tempDataIQ$humidity_lag <- as.numeric(lag_week_humid)

# select only the predictors we want for the model
iq_data_for_model <- select(tempDataIQ, total_cases, year, weekofyear, ndvi_ne, ndvi_nw, ndvi_se, ndvi_sw, precipitation_amt_mm, precip_lag, station_avg_temp_c, temp_lag, reanalysis_relative_humidity_percent, humidity_lag, )

```

```{r produceDataForModels}
iq_data_for_model <- filter(iq_data_for_model, humidity_lag != "NA")
sj_data_for_model <- filter(sj_data_for_model, humidity_lag != "NA")

# get good names for columns
iq_data_for_model <- iq_data_for_model %>% rename(week_of_year = weekofyear)
sj_data_for_model <- sj_data_for_model %>% rename(week_of_year = weekofyear)
```

```{r}
# write data for model use to files for later use
write.csv(sj_data_for_model, file = "sj_data_for_model.csv")
write.csv(iq_data_for_model, file = "iq_data_for_model.csv")
```


## Building a Model

`
sj_model <- train(total_cases ~ ., data = sj_data_for_model, method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 1:12), importance = TRUE)
sj_model
sj_model <- train(total_cases ~ ., data = sj_data_for_model, method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 11), importance = TRUE)
sj_model

iq_model <- train(total_cases ~ ., data = iq_data_for_model, method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 1:12), importance = TRUE)
iq_model
`


The Driven Data team uses Mean Absolute Error to measure error, so we will, too.

# Model Assessment

## Timeless Model

```{r}
test <- sample_n(sj_data_for_model, 0.1*length(sj_data_for_model$total_cases))
train <- anti_join(sj_data_for_model, test)

set.seed(92)
sj_model <- train(total_cases ~ ., data = select(train, -year, -week_of_year), method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 1:10), importance = TRUE)
sj_model
set.seed(82)
sj_model <- train(total_cases ~ ., data = sj_data_for_model, method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 8), importance = TRUE)
sj_model

predictions <- predict(sj_model, test)
RMSE(predictions - test$total_cases)
```

```{r}
test <- sample_n(iq_data_for_model, 0.1*length(iq_data_for_model$total_cases))
train <- anti_join(iq_data_for_model, test)

set.seed(92)
iq_model <- train(total_cases ~ ., data = select(train, -year, -week_of_year), method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 1:10), importance = TRUE)
iq_model
set.seed(82)
iq_model <- train(total_cases ~ ., data = iq_data_for_model, method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 1), importance = TRUE)
iq_model

predictions <- predict(iq_model, test)
RMSE(predictions - test$total_cases)
```

RMSE= 

```{r}
# returns Mean Absolute Error
# error is defined as actual - predicted
MAE <- function(error)
{
    mean(abs(error))
}

# returns Root Mean Squared Error
# error is defined as actual - predicted
RMSE <- function(error)
{
  sqrt(mean(error^2))
}
```

As Kane et. al used in their time series Random Forest model, the model was assessed by doing the following: "The simulation begins by using data from the last 30 weeks of data from 2006 to predict the outbreak for the week of 2007 (2007-01-07). The simulation proceeds by iteratively adding a new week of data, training a new model based on the updated data, and predicting the number of outbreaks for the following week."

Moving in steps of 30 weeks, we train the model on 30 weeks, then predict the next week. 

We'll assess our model's performance by computing the error (MSE) between the model's predicted number of cases and the actual number of cases for each week.

## San Juan Model Assessment

```{r}
step <- 30
predictions <- rep(NA, step)

index_to_predict = step + 1
while(index_to_predict <= length(sj_data_for_model$total_cases)) {

  # use previous "step" number of weeks to build model
  data <- slice(sj_data_for_model, (index_to_predict-step):(index_to_predict-1))
  
  model <- train(total_cases ~ ., data = data, method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 1:12), importance = TRUE)
  
  # predict on single observation:  the next week, the index_to_predict
  predicted_num_cases <- predict(model, slice(sj_data_for_model, index_to_predict))
  
  predictions <- c(predictions, predicted_num_cases)
  
  index_to_predict = index_to_predict + 1
}

actual <- sj_data_for_model$total_cases[31:length(sj_data_for_model$total_cases)]
predicted <- predictions[31:length(predictions)]

RMSE(predicted - actual)
MAE(predicted - actual)

# ranges from 0 to 100, scaled to data
nrmse(predicted, actual)
```

```{r}
sj_prospective_preds <- data.frame(sj_data_for_model$year[31:length(sj_data_for_model$total_cases)], sj_data_for_model$week_of_year[31:length(sj_data_for_model$total_cases)], actual, predicted)
colnames(sj_prospective_preds) = c("year", "week_of_year", "actual", "predicted")
sj_prospective_preds <- sj_prospective_preds %>% mutate(week_index = row_number()) %>% gather(actual_or_predicted, dengue_cases_in_week, -year, -week_of_year, -week_index)

ggplot(sj_prospective_preds, aes(x = week_index, y = dengue_cases_in_week, col = actual_or_predicted)) + geom_line() + ggtitle("San Juan: Actual vs. Predicted Weekly Dengue Cases")
```


## Iquitos Model Assessment

```{r}
step <- 30
predictions <- rep(NA, step)

index_to_predict = step + 1
while(index_to_predict <= length(iq_data_for_model$total_cases)) {

  # use previous "step" number of weeks to build model
  data <- slice(iq_data_for_model, (index_to_predict-step):(index_to_predict-1))
  
  model <- train(total_cases ~ ., data = data, method = "rf", trControl =  trainControl(method = "oob"), ntree = 500, tuneGrid = data.frame(mtry = 1:12), importance = TRUE)
  
  # predict on single observation:  the next week, the index_to_predict
  predicted_num_cases <- predict(model, slice(iq_data_for_model, index_to_predict))
  
  predictions <- c(predictions, predicted_num_cases)
  
  index_to_predict = index_to_predict + 1
}

actual <- iq_data_for_model$total_cases[31:length(iq_data_for_model$total_cases)]
predicted <- predictions[31:length(predictions)]

RMSE(predicted - actual)
MAE(predicted - actual)

nrmse(predicted, actual)
```

RMSE = 9.351698

```{r}
iq_prospective_preds <- data.frame(iq_data_for_model$year[31:length(iq_data_for_model$total_cases)], iq_data_for_model$week_of_year[31:length(iq_data_for_model$total_cases)], actual, predicted)
colnames(iq_prospective_preds) = c("year", "week_of_year", "actual", "predicted")
iq_prospective_preds <- iq_prospective_preds %>% mutate(week_index = row_number()) %>% gather(actual_or_predicted, dengue_cases_in_week, -year, -week_of_year, -week_index)

ggplot(iq_prospective_preds, aes(x = week_index, y = dengue_cases_in_week, col = actual_or_predicted)) + geom_line() + ggtitle("Iquitos : Actual vs. Predicted Weekly Dengue Cases")
```
